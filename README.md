ğŸ“˜ Scraper de Dados com Python

Um projeto simples e eficiente de Web Scraping usando Requests + BeautifulSoup e armazenando os dados em um banco local SQLite.
Ideal para aprender automaÃ§Ã£o, coleta de dados e persistÃªncia em banco usando Python.

ğŸš€ Tecnologias Utilizadas

Python 3

Requests â€” para realizar requisiÃ§Ãµes HTTP

BeautifulSoup (bs4) â€” para extrair dados da pÃ¡gina

SQLite â€” banco de dados local

VS Code â€” ambiente de desenvolvimento

ğŸ“‚ Estrutura do Projeto
ğŸ“ scraper-projeto
â”‚
â”œâ”€â”€ scraper.py          # Script principal do scraper
â”œâ”€â”€ database.py         # ConexÃ£o e inserÃ§Ã£o no banco SQLite
â”œâ”€â”€ dados.db            # Banco de dados gerado automaticamente
â””â”€â”€ README.md           # DocumentaÃ§Ã£o do projeto

ğŸ•¸ Como Funciona o Scraper

Acessa uma pÃ¡gina web utilizando requests.get().

Extrai dados usando BeautifulSoup.

Armazena cada item coletado dentro do SQLite.

Permite reuso e expansÃ£o para qualquer outro site.

â–¶ Como Rodar o Projeto
1. Instale os requisitos:
pip install requests beautifulsoup4

2. Execute o scraper:
python scraper.py


O arquivo dados.db serÃ¡ criado automaticamente com as informaÃ§Ãµes coletadas.

ğŸ—„ Estrutura do Banco de Dados

Tabela padrÃ£o:

CREATE TABLE dados (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    titulo TEXT,
    link TEXT
);


Cada execuÃ§Ã£o do scraper adiciona novos registros.

ğŸ§© PossÃ­veis ExtensÃµes

VocÃª pode evoluir esse projeto adicionando:

Scrapy (framework avanÃ§ado de scraping)

Armazenamento em PostgreSQL

Dashboard usando Streamlit

ExportaÃ§Ã£o para CSV, Excel ou API REST

ğŸ’¼ Ideal Para PortfÃ³lio

Esse projeto demonstra:

âœ” domÃ­nio de Python
âœ” lÃ³gica de programaÃ§Ã£o e automaÃ§Ã£o
âœ” manipulaÃ§Ã£o de dados reais
âœ” persistÃªncia em banco de dados
âœ” organizaÃ§Ã£o de projeto
âœ” uso correto de Git e GitHub